{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e5d13a",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "Please submit the solution to gradescope by 11:59 PM, Sept 26, Thursday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96503059",
   "metadata": {},
   "source": [
    "**Name**: \n",
    "\n",
    "**PID**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b80ed",
   "metadata": {},
   "source": [
    "# Problem 1  Sales Data Analysis (35 Points)\n",
    "**Dataset:** You will work with a simulated dataset representing the monthly sales data for a fictional company over a period of 3 years (36 months). The dataset is provided as a NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207a397",
   "metadata": {
    "id": "znxePhz1kqd4"
   },
   "source": [
    "### 1.0 . Setup and Initialization\n",
    "\n",
    "Import NumPy and initialize the dataset as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f44541",
   "metadata": {
    "id": "F5mMB96sp8HS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sales_data = np.array([207, 217, 244, 269, 247, 248, 273, 260, 243, 265, 263, 280,\n",
    "                       310, 296, 313, 340, 336, 356, 335, 327, 374, 358, 376, 372,\n",
    "                       405, 432, 425, 455, 443, 446, 439, 477, 454, 449, 494, 482])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e904f",
   "metadata": {
    "id": "qin2HvyclrJs"
   },
   "source": [
    "### 1.1 Monthly Analysis (15 Points)\n",
    "Using the `sales_data` array, perform the following tasks:\n",
    "1. Calculate the total sales for each year, and store the result in a NumPy array `total_sales_per_year`. Display the `total_sales_per_year`. (2 points)\n",
    "\n",
    "2. Calculate the average monthly sales for each year, and store the result in a NumPy array `average_monthly_sales_per_year`. Display the `average_monthly_sales_per_year`. (2 points)\n",
    "\n",
    "3. Calculate the average season sales for each year, and store the result in a `3` by `4` NumPy array `average_season_sales_per_year`. Each row represent a year, and each column represent a season. Display the `average_season_sales_per_year`. (6 points)\n",
    "\n",
    "4. Identify the month with the highest sales and the month with the lowest sales on average over the three year period. Store the numerical representation (1-12) of the month in the variables `max_sales_month` and `min_sales_month`. (5 points)\n",
    "\n",
    "You can assume the years are in chronological order. For example, the first value represents sales in January of Year 1 and the last value represents sales in December of Year 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694ed4e",
   "metadata": {
    "id": "EK2htmDFl96J"
   },
   "source": [
    "### 1.2 Growth Rate Calculation (5 Points)\n",
    "Write a function `calculate_growth_rate(data)` that takes the `sales_data` array as input and returns the growth rates for each month in a NumPy array. You can assume the growth rate for the first month is 0.01.\n",
    "\n",
    "Calculate the monthly growth rate of sales using the formula:\n",
    "\n",
    "$$\\text{growth_rate}[i] = \\frac{\\text{sales_data}[i] - \\text{sales_data}[i-1]}{\\text{sales_data}[i-1]}$$\n",
    "\n",
    "Display the result of `calculate_growth_rate(sales_data)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc4dc2",
   "metadata": {
    "id": "MA5ufhizT8OI"
   },
   "source": [
    "### 1.3 Growth Rate Summary (5 Points)\n",
    "Identify the following months:\n",
    "\n",
    "*   The months in the past three years saw the largest increase and the largest decrease in sales (i.e. from January to February of Year 1 we saw the largest decrease in sales)\n",
    "*   The month on average with the largest increase and largest decrease in sales\n",
    "\n",
    "Show both the python code and conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b8b77",
   "metadata": {
    "id": "G21OsK_la3N5"
   },
   "source": [
    "### 1.4 Moving Average (5 points)\n",
    "\n",
    "Calculate the 3-month moving average of the `sales_data` and store the result in a NumPy array called `moving_average`. The calculation starts from the third month in Year 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf7866",
   "metadata": {},
   "source": [
    "The three-period moving average for month $t$ is calculated as:\n",
    "\n",
    "\n",
    "$$\\text{MA}_3(t) = \\frac{x_t + x_{t-1} + x_{t-2}}{3}.$$\n",
    "\n",
    "Where:\n",
    "- $x_t$ is the sales in month $t$,\n",
    "- $x_{t-1}$ is the sales in month $t-1$,\n",
    "- $x_{t-2}$ is the sales in month $t-2$.\n",
    "\n",
    "Display the `moving_average`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7604e",
   "metadata": {
    "id": "GA8BdljscD_6"
   },
   "source": [
    "### 1.5 Sales Anomaly Detection (5 points)\n",
    "\n",
    "Write a function `sales_anomaly_detection(sales_data)` that takes the `sales_data` array as input, identify months where sales were significantly higher or lower than the previous month's sales (more than 12% change), and returns a dictionary mapping the month number (1-36) to the sales data for all anomalous months.\n",
    "\n",
    "Display the result of `sales_anomaly_detection(sales_data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904729e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515fc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e94e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf2eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c2684b",
   "metadata": {
    "id": "Ow2Ek3aODGPe"
   },
   "source": [
    "# Problem 2: Analysis on the diamonds dataset (65 points)\n",
    "\n",
    "Here is a brief description of the key columns in the **`diamonds`** dataset from Seaborn:\n",
    "\n",
    "\n",
    "**`Carat`**: The weight of the diamond (continuous variable). Larger diamonds have higher carat values.\n",
    "\n",
    "\n",
    "**`Cut`**: The quality of the diamond's cut (categorical variable).\n",
    "\n",
    "\n",
    "**`Color`**: The diamond’s color grade (categorical variable). \n",
    "\n",
    "\n",
    "**`Clarity`**: The clarity of the diamond (categorical variable), which indicates how free the diamond is from internal flaws (inclusions) or external blemishes. It ranges from `IF` (Internally Flawless) to `I3` (Included).\n",
    "\n",
    "\n",
    "**`Depth`**: The total depth percentage (continuous variable). It’s the ratio of the depth of the diamond to its average diameter.\n",
    "\n",
    "\n",
    "**`Table`**: The width of the diamond’s top relative to its widest point (expressed as a percentage).\n",
    "\n",
    "\n",
    "**`Price`**: The price of the diamond in US dollars (continuous variable).\n",
    "\n",
    "\n",
    "**`x`**: Length of the diamond in millimeters (continuous variable).\n",
    "\n",
    "\n",
    "**`y`**: Width of the diamond in millimeters (continuous variable).\n",
    "\n",
    "\n",
    "**`z`**: Depth of the diamond in millimeters (continuous variable).\n",
    "\n",
    "This dataset provides valuable features for exploring the relationship between various attributes and the price of diamonds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec62c11",
   "metadata": {},
   "source": [
    "#### 2.1 Load the dataset from a `diamonds.csv`. (1 point)\n",
    "\n",
    "#### 2.2 How many different levels are there in the `cut` column? Provide the names of all levels. (4 points)\n",
    "\n",
    "#### 2.3 Create three new columns, `x_in_inch`, `y_in_inch`, and `z_in_inch`, which convert the units of the original `x`, `y`, and `z` from millimeters to inches. Print the new table. (5 points)\n",
    "\n",
    "#### 2.4 Create a new column called `Normalized_depth`, which scales the depth values between 0 and 1. (10 points)\n",
    "\n",
    "The equation to normalize the `depth` column is given as:\n",
    "\n",
    "$$\n",
    "\\text{depth}_{\\text{normalized}} = \\frac{\\text{depth} - \\min(\\text{depth})}{\\max(\\text{depth}) - \\min(\\text{depth})}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\text{depth} $ is the original value,\n",
    "- $ \\min(\\text{depth}) $ is the minimum value in the `depth` column,\n",
    "- $ \\max(\\text{depth}) $ is the maximum value in the `depth` column.\n",
    "\n",
    "Print the new table.\n",
    "\n",
    "#### 2.5 Select the rows from the entire table where `clarity` is `SI2`. Drop the columns `color` and `clarity`. Print the selected table. (5 points)\n",
    "\n",
    "#### 2.6 Suppose we have a linear model that predicts the price of a diamond using the `carat` value:\n",
    "\n",
    "$$\n",
    "\\text{Predicted Price}  = 7769 \\times \\text{carat} - 2262.\n",
    "$$\n",
    "\n",
    "In the selected table from 2.5, create a new column called `Predicted_Price`, which contains the predicted price using the above formula. Display the new table. (10 points)\n",
    "\n",
    "#### 2.7 In the new table from 2.6, calculate the difference between the actual price and the predicted price. How many rows have a prediction error that is smaller than 20% of the actual price? (5 points)\n",
    "\n",
    "#### 2.8 Sort the table in 2.7 by 'carat' column in increasing order. Display the first 3 rows and last 3 rows of the sorted table. (5 points). Concatenate the first 3 rows and last 3 rows into a new table. (5 points) (10 points in total)\n",
    "\n",
    "#### 2.9 In the table from 2.7, what is the value of `carat` that has the smallest prediction error? What is the value of `carat` that has the largest prediction error. (5 points)\n",
    "\n",
    "#### 2.10 In the orignal entire table, calculate the average prices for each level of cut. Display the result as a pd.Series. Does a better cut lead to a higher price? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4e75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbde716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a59727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
