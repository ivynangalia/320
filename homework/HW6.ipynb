{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e5d13a",
   "metadata": {},
   "source": [
    "# STOR 320 Homework 6 Cross Validation\n",
    "\n",
    "Please submit the solution to gradescope by 11:59 PM, Nov 21, Thursday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96503059",
   "metadata": {},
   "source": [
    "**Name**: \n",
    "\n",
    "**PID**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35a1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f55d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogSalePrice</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PreCast</th>\n",
       "      <th>Stone</th>\n",
       "      <th>Stucco</th>\n",
       "      <th>VinylSd</th>\n",
       "      <th>WdSdng</th>\n",
       "      <th>WdShing</th>\n",
       "      <th>WdShng</th>\n",
       "      <th>YearsSince1950Built</th>\n",
       "      <th>YearsSince1950Remod</th>\n",
       "      <th>YearsSince1950GarageBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.278393</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NoAccess</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.561716</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NoAccess</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.055250</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NoAccess</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.404924</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NoAccess</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.154253</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NoAccess</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LogSalePrice MSSubClass MSZoning  LotFrontage  LotArea Street     Alley  \\\n",
       "0     12.278393         20       RL        141.0  31770.0   Pave  NoAccess   \n",
       "1     11.561716         20       RH         80.0  11622.0   Pave  NoAccess   \n",
       "2     12.055250         20       RL         81.0  14267.0   Pave  NoAccess   \n",
       "3     12.404924         20       RL         93.0  11160.0   Pave  NoAccess   \n",
       "4     12.154253         60       RL         74.0  13830.0   Pave  NoAccess   \n",
       "\n",
       "  LotShape LandContour Utilities  ... PreCast Stone Stucco VinylSd WdSdng  \\\n",
       "0      IR1         Lvl    AllPub  ...       0     0      0       0      0   \n",
       "1      Reg         Lvl    AllPub  ...       0     0      0       1      0   \n",
       "2      IR1         Lvl    AllPub  ...       0     0      0       0      1   \n",
       "3      Reg         Lvl    AllPub  ...       0     0      0       0      0   \n",
       "4      IR1         Lvl    AllPub  ...       0     0      0       1      0   \n",
       "\n",
       "  WdShing WdShng YearsSince1950Built YearsSince1950Remod  \\\n",
       "0       0      0                  10                  10   \n",
       "1       0      0                  11                  11   \n",
       "2       0      0                   8                   8   \n",
       "3       0      0                  18                  18   \n",
       "4       0      0                  47                  48   \n",
       "\n",
       "  YearsSince1950GarageBuilt  \n",
       "0                      10.0  \n",
       "1                      11.0  \n",
       "2                       8.0  \n",
       "3                      18.0  \n",
       "4                      47.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames = pd.read_feather('cleaned_ames.feather')\n",
    "ames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c710d",
   "metadata": {},
   "source": [
    "1. **Load the cleaned Ames dataset. Convert the categorical variables into dummy variables. Display the new `ames` table. How many columns are there? (5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045a3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_dummies = pd.get_dummies(ames)\n",
    "len(ames_dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf9b5e",
   "metadata": {},
   "source": [
    "2.  **L1 Distance Calculation (5 points)**\n",
    "   - Define the L1 distance between two rows as the sum of the absolute values of the differences for all features. Calculate the L1 distance between the first and second rows of the dataset.\n",
    "   \n",
    "   - For Boolean variables, you can treat `True` as 1 and `False` as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f803bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice = ames_dummies[:2]\n",
    "# convert boolean to int\n",
    "slice = slice.astype(int)\n",
    "L1 = np.sum(np.abs(slice.iloc[0] - slice.iloc[1]))\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f498bb5",
   "metadata": {},
   "source": [
    "3. **Feature Matrix and Target Vector Creation (10 points)**\n",
    "   - Create a feature matrix `X` by dropping the `LogSalePrice` column from the dataset. Create a target vector `y` using the `LogSalePrice` column. (5 points)\n",
    "   - Randomly split `X` and `y` into training and test sets with a 70/30 split. Name the training set `X_train` and `y_train`, and the test set `X_test` and `y_test`. Use random seed as `42`. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5152fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ames_dummies[\"LogSalePrice\"]\n",
    "X = ames_dummies.drop(columns=[\"LogSalePrice\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13d4c4",
   "metadata": {},
   "source": [
    "4. **Rescaling the Feature Matrix (5 points)**\n",
    "   - Rescale the values of `X_train` using a scaler (e.g., `StandardScaler`). Use the same scaling rule to transform `X_test`. Name the transformed sets `X_train_scaled` and `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb4ce312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1935, 381), (830, 381)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"{X_train_scaled.shape}, {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0f6cf",
   "metadata": {},
   "source": [
    "5. **Simple L1 Prediction Model (10 points)**\n",
    "   - Implement a simple prediction model: For each row in `X_test_scaled`, find the closest row in `X_train_scaled` in terms of L1 distance. Use the corresponding `y` value from `y_train` as the prediction.\n",
    "   - Create predictions for all observations in `X_test_scaled` and name the prediction array `y_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6030bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(X_test_scaled)):\n",
    "    L1_distances = np.sum(np.abs(X_train_scaled - X_test_scaled[i]), axis=1)\n",
    "    closest_index = np.argmin(L1_distances)\n",
    "    y_predict.append(y_train.iloc[closest_index])\n",
    "y_predict = np.array(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbffe3",
   "metadata": {},
   "source": [
    "6. **Calculate Out-of-Sample R-squared (OSR2)  (5 points)**\n",
    "   - Calculate the OSR2 (out-of-sample R-squared) for the predictions from Problem 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f2e9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSR2(y_train, y_test, y_pred):\n",
    "    \n",
    "    SSE = np.sum((y_test - y_pred)**2)\n",
    "    SST = np.sum((y_test - np.mean(y_train))**2)\n",
    "                 \n",
    "    return (1 - SSE/SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "211b5c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR2: 0.7396347150902295\n"
     ]
    }
   ],
   "source": [
    "print(f\"OSR2: {OSR2(y_train, y_test, y_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a47c1a",
   "metadata": {},
   "source": [
    "7. **Flexible L1 Prediction Model (10 points)**\n",
    "   - Modify the prediction rule: For each row in `X_test_scaled`, find the five closest rows in `X_train_scaled` in terms of L1 distance and use the average `y` value of these five observations as the prediction.\n",
    "   - Create predictions for all observations in `X_test_scaled` and name the prediction array `y_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a24692cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(X_test_scaled)):\n",
    "    L1_distances = np.sum(np.abs(X_train_scaled - X_test_scaled[i]), axis=1)\n",
    "    closest_indices = np.argsort(L1_distances)[:5]\n",
    "    y_predict.append(np.mean(y_train.iloc[closest_indices]))\n",
    "y_predict = np.array(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8571418",
   "metadata": {},
   "source": [
    "8. **Calculate OSR2 for the Modified Model (5 points)**\n",
    "   - Calculate the OSR2 for the predictions from Problem 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c159459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR2: 0.7969887360628379\n"
     ]
    }
   ],
   "source": [
    "print(f\"OSR2: {OSR2(y_train, y_test, y_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9483b8",
   "metadata": {},
   "source": [
    "9. **KNN Model Using Sklearn (10 points)**\n",
    "\n",
    "   The above idea is called `K-Nearest Neighbors`. The K-Nearest Neighbors (KNN) algorithm is a non-parametric method used for regression and classification. It predicts the target for a new observation by averaging the target values of its k nearest training samples. This method is effective for capturing local structures in the data, which can lead to more flexible predictions compared to global linear models.\n",
    "   - Use the `KNeighborsRegressor(n_neighbors=k, metric='cityblock')` function in `sklearn` to build a KNN model with `k=5`. `metric='cityblock'` represents the L1 norm distance. (5 points)\n",
    "   \n",
    "   - Print the OSR2 of the model. Is your OSR2 the same as the OSR2 in Problem 8? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e65b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR2: 0.7969887360628379\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsRegressor(n_neighbors=5, metric='cityblock')\n",
    "KNN.fit(X_train_scaled, y_train)\n",
    "y_predict = KNN.predict(X_test_scaled)\n",
    "print(f\"OSR2: {OSR2(y_train, y_test, y_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f2e12",
   "metadata": {},
   "source": [
    "10. **Effect of Large k (5 points)**\n",
    "   - Explain what happens when `k` equals the size of the training set. What is the predicted value in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a96110be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR2: 0.0\n",
      "y_predict is all the same value. (12.047640175621291)\n"
     ]
    }
   ],
   "source": [
    "k = len(X_train_scaled)\n",
    "KNN = KNeighborsRegressor(n_neighbors=k, metric='cityblock')\n",
    "KNN.fit(X_train_scaled, y_train)\n",
    "y_predict = KNN.predict(X_test_scaled)\n",
    "print(f\"OSR2: {OSR2(y_train, y_test, y_predict)}\")\n",
    "print(f\"y_predict is all the same value. ({y_predict.mean()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93feb96d",
   "metadata": {},
   "source": [
    "11. **Model Bias and Overfitting Discussion (5 points)**\n",
    "    - Discuss how the model behaves as `k` increases. Does the model become more biased or less biased? Does it overfit more or less as `k` increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5572b8e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1935, 830]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     y_predict \u001b[38;5;241m=\u001b[39m KNN\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m     12\u001b[0m     OSR2_list\u001b[38;5;241m.\u001b[39mappend(OSR2(y_train, y_test, y_predict))\n\u001b[0;32m---> 13\u001b[0m     R2_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(k_range, OSR2_list, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOSR2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_regression.py:1204\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m   1198\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[1;32m   1199\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1202\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1204\u001b[0m _, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 111\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1935, 830]"
     ]
    }
   ],
   "source": [
    "k_range = np.logspace(0.1, 3, num=50)  \n",
    "k_range = k_range.astype(int)\n",
    "k_range = np.unique(k_range)  \n",
    "\n",
    "R2_list = []\n",
    "OSR2_list = []\n",
    "for k in k_range:\n",
    "    \n",
    "    KNN = KNeighborsRegressor(n_neighbors=k, metric='cityblock')\n",
    "    KNN.fit(X_train_scaled, y_train)\n",
    "    y_predict = KNN.predict(X_test_scaled)\n",
    "    OSR2_list.append(OSR2(y_train, y_test, y_predict))\n",
    "    R2_list.append(r2_score(y_train, y_predict))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, OSR2_list, color='blue', label='OSR2')\n",
    "plt.plot(k_range, R2_list, color='red', label='R2')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of neighbors (k)')\n",
    "plt.ylabel('Out-of-Sample RÂ²')\n",
    "plt.title('Effect of k on Model Performance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7893919",
   "metadata": {},
   "source": [
    "12. **Parameter Tuning with GridSearchCV (20 points)**\n",
    "    - Create a custom function called `Mean_Absolute_Price_Error()` that converts the predicted log prices back to the original prices and calculates the Mean Absolute Error (MAE) between the predicted prices and true prices. (5 points)\n",
    "    - Use `GridSearchCV` to tune the `k` parameter of the KNN model, using the custom `Mean_Absolute_Price_Error()` function as the metric for model selection. Use `5-fold` cross validation. (5 points)\n",
    "    - Plot the `MAE` for different values of `k`. (5 points)\n",
    "    - Identify the `k` value that results in the smallest `Mean_Absolute_Price_Error`. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05446d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e23f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2235f3f5",
   "metadata": {},
   "source": [
    "13. **Refit the Model (5 points)**\n",
    "    - Refit the KNN model using the optimal `k` value from Problem 12. Print the out-of-sample performance (R2) of this final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579acf53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
