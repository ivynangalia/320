{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOR 320 Introduction to Data Science\n",
    "\n",
    "## Week 10: Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSR2(y_train, y_test, y_pred):\n",
    "    \n",
    "    SSE = np.sum((y_test - y_pred)**2)\n",
    "    SST = np.sum((y_test - np.mean(y_train))**2)\n",
    "                 \n",
    "    return (1 - SSE/SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_test, y_pred):\n",
    "    \n",
    "    return (np.mean(abs(y_test - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_test, y_pred):\n",
    "    \n",
    "    return np.sqrt(np.mean((y_test - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, X_train, y_train, X_test, y_test, flag_log_sale_price=False):\n",
    "\n",
    "    if (flag_log_sale_price == True):\n",
    "        \n",
    "        y_pred_train = pd.Series(model.predict(X_train)).reset_index(drop=True)\n",
    "        y_pred_test = pd.Series(model.predict(X_test)).reset_index(drop=True)\n",
    "        y_train = y_train.copy().reset_index(drop=True)\n",
    "        y_test = y_test.copy().reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\nMetrics for Log(Sale Price):\\n\")\n",
    "        \n",
    "    elif (flag_log_sale_price == False):\n",
    "        \n",
    "        y_pred_train = pd.Series(model.predict(X_train)).apply(np.exp).reset_index(drop=True)\n",
    "        y_pred_test = pd.Series(model.predict(X_test)).apply(np.exp).reset_index(drop=True)\n",
    "        y_train = y_train.copy().apply(np.exp).reset_index(drop=True)\n",
    "        y_test = y_test.copy().apply(np.exp).reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\nMetrics for Sale Price:\\n\")\n",
    "\n",
    "    print('Training R2', OSR2(y_train, y_train, y_pred_train))\n",
    "    print('Training MAE', MAE(y_train, y_pred_train))\n",
    "    print('Training RMSE', RMSE(y_train, y_pred_train))\n",
    "\n",
    "    print('Out-of-sample R2', OSR2(y_train, y_test, y_pred_test))\n",
    "    print('Out-of-sample MAE', MAE(y_test, y_pred_test))\n",
    "    print('Out-of-sample RMSE', RMSE(y_test, y_pred_test))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2765 entries, 0 to 2764\n",
      "Columns: 105 entries, Unnamed: 0 to YearsSince1950GarageBuilt\n",
      "dtypes: float64(21), int64(45), object(39)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ames = pd.read_csv('cleaned_Ames.csv')\n",
    "ames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ames \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_ames.feather\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ames\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/feather_format.py:117\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_feather\u001b[39m(\n\u001b[1;32m     74\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    Load a feather-format object from the file path.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feather\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "ames = pd.read_feather('cleaned_ames.feather')\n",
    "ames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_train = ames.loc[ames['YrSold'].isin([2006, 2007, 2008])]\n",
    "ames_test = ames.loc[ames['YrSold'].isin([2009, 2010])]\n",
    "\n",
    "ames = ames.drop(columns = ['YrSold'])\n",
    "ames_train = ames_train.drop(columns = ['YrSold'])\n",
    "ames_test = ames_test.drop(columns = ['YrSold'])\n",
    "\n",
    "y_train = ames_train['LogSalePrice']\n",
    "y_test = ames_test['LogSalePrice']\n",
    "\n",
    "print(ames.shape, ames_train.shape, ames_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear model with higher-order Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polynomial_features(df, n_degree):\n",
    "\n",
    "    new_df = None\n",
    "    \n",
    "    for i in range(2, n_degree+1):\n",
    "        \n",
    "        tmp = df.pow(i)\n",
    "        \n",
    "        affix = '_p'+str(i)\n",
    "        tmp.columns = list(map(lambda x: x + affix, df.columns))\n",
    "        \n",
    "        if new_df is not None:\n",
    "            new_df = pd.concat([new_df, tmp], axis=1)\n",
    "        else:\n",
    "            new_df = tmp\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>\n",
    "    \n",
    "NOTE: An important consideration when creating higher-order variables is that the resulting features will tend to have some degree of linear dependence amongst themselves. This is normal as several new features are based on their zero-th power peer. Such correlation can also yield a high degree of multicollinearity in the regression models. The `sklearn` implementations that we will be using do not automatically account for this phenomenon, therefore we must be careful in selection the `n_degree`, and analyzing the model fit. \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only choose a select list of variables to do polynomial transformation.\n",
    "poly_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "             'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "             'EnclosedPorch', 'X3SsnPorch', 'ScreenPorch', 'MiscVal', 'YearsSince1950Built',\n",
    "             'YearsSince1950Remod', 'YearsSince1950GarageBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_degree = 2\n",
    "\n",
    "train_poly_temp = create_polynomial_features(ames_train[poly_cols], n_degree)\n",
    "test_poly_temp = create_polynomial_features(ames_test[poly_cols], n_degree)\n",
    "\n",
    "ames_train_poly = pd.concat([ames_train, train_poly_temp], axis=1)\n",
    "ames_test_poly = pd.concat([ames_test, test_poly_temp], axis=1)\n",
    "\n",
    "print(ames_train.shape, ames_test.shape)\n",
    "print(train_poly_temp.shape, test_poly_temp.shape)\n",
    "print(ames_train_poly.shape, ames_test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ames_train_poly.shape)\n",
    "all_columns = \"+\".join(ames_train_poly.columns.difference([\"LogSalePrice\"]))\n",
    "my_formula = \"LogSalePrice~\" + all_columns +'-1'\n",
    "print(my_formula)\n",
    "\n",
    "mod_naive_poly = smf.ols(my_formula, data=ames_train_poly)\n",
    "nlr_poly = mod_naive_poly.fit()\n",
    "\n",
    "print(nlr_poly.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_metrics(nlr_poly, ames_train_poly, y_train, ames_test_poly, y_test, flag_log_sale_price = True)\n",
    "print_metrics(nlr_poly, ames_train_poly, y_train, ames_test_poly, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = ames_train_poly.drop(columns='LogSalePrice')\n",
    "X_test_poly = ames_test_poly.drop(columns='LogSalePrice')\n",
    "\n",
    "X_train_poly_wide = pd.get_dummies(X_train_poly)\n",
    "X_test_poly_wide = pd.get_dummies(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso = X_train_poly_wide\n",
    "X_test_lasso = X_test_poly_wide\n",
    "\n",
    "print(X_train_lasso.shape, X_test_lasso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-2\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-5\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-6\n",
    "lasso = Lasso(alpha=alpha, random_state=88)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_list = []\n",
    "candidate_values = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "for alpha in candidate_values:\n",
    "    lasso = Lasso(alpha=alpha, random_state=88)\n",
    "    lasso.fit(X_train_lasso, y_train)\n",
    "    y_pred_test = pd.Series(lasso.predict(X_test_lasso)).apply(np.exp).reset_index(drop=True)\n",
    "    y_train_exp = y_train.copy().apply(np.exp).reset_index(drop=True)\n",
    "    y_test_exp = y_test.copy().apply(np.exp).reset_index(drop=True)\n",
    "    MAE_list.append(MAE(y_test_exp, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(candidate_values, MAE_list,'o-', markersize = 5)\n",
    "plt.xlabel('Value of lambda')\n",
    "plt.ylabel('OSR2')\n",
    "plt.xscale('log') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-class activity 1: Create a similar plot for Ridge regression. The candidate value for labmda is `[ 1e-1, 1, 10, 1e2, 1e3, 1e4 ]`. Y-axis is the OSR2 and X-axis is the value of lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Training set performance to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingMAE_list = []\n",
    "candidate_values = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "for alpha in candidate_values:\n",
    "    lasso = Lasso(alpha=alpha, random_state=88)\n",
    "    lasso.fit(X_train_lasso, y_train)\n",
    "    y_pred_train = pd.Series(lasso.predict(X_train_lasso)).apply(np.exp).reset_index(drop=True)\n",
    "    y_train_exp = y_train.copy().apply(np.exp).reset_index(drop=True)\n",
    "    y_test_exp = y_test.copy().apply(np.exp).reset_index(drop=True)\n",
    "    TrainingMAE_list.append(MAE(y_train_exp, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(candidate_values, MAE_list,'o-', markersize = 5, label = 'Out-of-sample')\n",
    "plt.plot(candidate_values, TrainingMAE_list,'o-', markersize = 5, label = 'In-sample')\n",
    "plt.xlabel('Value of lambda')\n",
    "plt.ylabel('')\n",
    "plt.xscale('log') \n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "alpha_grid = {'alpha': np.logspace(-8, -1, num=10, base=10)}\n",
    "\n",
    "lasso_cv = GridSearchCV(lasso, param_grid = alpha_grid, scoring='neg_mean_squared_error', cv=10, verbose=1)\n",
    "lasso_cv.fit(X_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def one_standard_error_rule(model, results, param_grid, n_splits, neg_mean_squared_error=True):\n",
    "    \n",
    "    assert neg_mean_squared_error == True # function is defined specifically for neg_mean_squared_error\n",
    "    \n",
    "    range_x = param_grid # results['param_'+list(param_grid.keys())[0]].data\n",
    "    std_vs_x  = pd.Series(results['std_test_score'], index = range_x)\n",
    "    sem_vs_x  = std_vs_x/np.sqrt(n_splits)\n",
    "    \n",
    "    mean_vs_x = pd.Series(results['mean_test_score'], index = range_x)        \n",
    "    mean_vs_x = mean_vs_x*(-1)\n",
    "    \n",
    "    x_min = mean_vs_x.idxmin()\n",
    "    sem = sem_vs_x[x_min]\n",
    "    \n",
    "    if (model=='pcr'):\n",
    "        x_1se = mean_vs_x[mean_vs_x <= min(mean_vs_x) + sem].index.min()\n",
    "    elif (model=='ridge') | (model=='lasso'):\n",
    "        x_1se = mean_vs_x[mean_vs_x <= min(mean_vs_x) + sem].index.max()\n",
    "        \n",
    "    #x_1se_idx = int(np.argwhere(range_x == x_1se)[0])\n",
    "    \n",
    "    return x_min, x_1se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = lasso_cv.cv_results_['param_alpha'].data\n",
    "MSE_scores = lasso_cv.cv_results_['mean_test_score']*(-1)\n",
    "x_min, x_1se = one_standard_error_rule(model='lasso',\n",
    "                                       results=lasso_cv.cv_results_,\n",
    "                                       param_grid=range_alpha,\n",
    "                                       n_splits=10,\n",
    "                                       neg_mean_squared_error=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Alpha', fontsize=16)\n",
    "plt.ylabel('CV MSE', fontsize=16)\n",
    "plt.scatter(range_alpha, MSE_scores, s=30)\n",
    "plt.plot(range_alpha, MSE_scores)\n",
    "plt.axvline(x=x_min, color='m')\n",
    "plt.axvline(x=x_1se, color='c')\n",
    "plt.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magenta vertical line is the minimizer, the cyan vertical line is the \"1 Standard Error\" selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lasso_cv.cv_results_['mean_test_score'] # what sklearn calls mean_test_score is the holdout set, i.e. the validation set.\n",
    "ccp = lasso_cv.cv_results_['param_alpha'].data\n",
    "\n",
    "pd.DataFrame({'ccp alpha' : ccp, 'Validation Accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alpha one standard error rule:', x_1se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Refit with One Standard Error Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = GridSearchCV(lasso, {'alpha': [x_1se]}, scoring='neg_mean_squared_error', cv=10)\n",
    "lasso_cv.fit(X_train_lasso, y_train)\n",
    "\n",
    "print_metrics(lasso_cv, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "#print_metrics(lasso_cv, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the dataset for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "alpha_grid = {'alpha': np.logspace(-8, -1, num=15, base=10)}\n",
    "cv = KFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "lasso_cv = GridSearchCV(lasso, param_grid = alpha_grid, scoring='neg_mean_squared_error', cv=cv, verbose=2)\n",
    "lasso_cv.fit(X_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = lasso_cv.cv_results_['param_alpha'].data\n",
    "MSE_scores = lasso_cv.cv_results_['mean_test_score']*(-1)\n",
    "x_min, x_1se = one_standard_error_rule(model='lasso',\n",
    "                                       results=lasso_cv.cv_results_,\n",
    "                                       param_grid=range_alpha,\n",
    "                                       n_splits=10,\n",
    "                                       neg_mean_squared_error=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Alpha', fontsize=16)\n",
    "plt.ylabel('CV MSE', fontsize=16)\n",
    "plt.scatter(range_alpha, MSE_scores, s=30)\n",
    "plt.plot(range_alpha, MSE_scores)\n",
    "plt.axvline(x=x_min, color='m')\n",
    "plt.axvline(x=x_1se, color='c')\n",
    "plt.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_prediction_error_count(y_test, y_pred, threshold = 2000):\n",
    "    y_pred_test = pd.Series(y_pred).copy().apply(np.exp).reset_index(drop=True)\n",
    "    y_test_exp = pd.Series(y_test).copy().apply(np.exp).reset_index(drop=True)\n",
    "    count = [(y_pred_test - y_test_exp) > 2000]\n",
    "    return np.sum(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer  \n",
    "\n",
    "alpha_grid = {'alpha': np.logspace(-8, -1, num=10, base=10)}\n",
    "cv = KFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "lasso_cv = GridSearchCV(lasso, param_grid = alpha_grid, scoring=make_scorer(large_prediction_error_count, greater_is_better=False), cv=cv, verbose=2)\n",
    "lasso_cv.fit(X_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = lasso_cv.cv_results_['param_alpha'].data\n",
    "new_scores = lasso_cv.cv_results_['mean_test_score']*(-1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Alpha', fontsize=16)\n",
    "plt.ylabel('Customized loss', fontsize=16)\n",
    "plt.scatter(range_alpha, new_scores, s=30)\n",
    "plt.plot(range_alpha, new_scores)\n",
    "plt.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation for Principal Components Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ames_train['LogSalePrice']\n",
    "y_test = ames_test['LogSalePrice']\n",
    "\n",
    "X_train_pcr = X_train_poly_wide\n",
    "X_test_pcr = X_test_poly_wide\n",
    "\n",
    "print(X_train_poly_wide.shape, X_train_pcr.shape)\n",
    "print(X_test_poly_wide.shape, X_test_pcr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also standardize the data before feeding it to the PCA step, as recommended by good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(random_state=88)\n",
    "lr = LinearRegression()\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('lr', lr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(pca__n_components=5)\n",
    "pipe.fit(X_train_pcr, y_train)\n",
    "print_metrics(pipe, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = True)\n",
    "print_metrics(pipe, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class activity 2: For PCR, do a 5 fold cross validation value for `n_components` in terms of the `R-squared`. The potential  `n_components` is between 1 and 300. \n",
    "- What are the best R2 value and its corresponding n_components? \n",
    "- What is the value of `n_components` according to the one standard error rule?\n",
    "- Refit the model using the `n_components` selected by the one standard error rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'pca__n_components': np.linspace(1, 300, 35).astype('int')}\n",
    "\n",
    "pcr_cv = GridSearchCV(pipe,\n",
    "                      param_grid,\n",
    "                      scoring='r2',\n",
    "                      cv=5,\n",
    "                     verbose = 2)\n",
    "pcr_cv.fit(X_train_pcr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "n_components = pcr_cv.cv_results_['param_pca__n_components'].data\n",
    "R2_scores = pcr_cv.cv_results_['mean_test_score']\n",
    "x_min, x_1se = one_standard_error_rule(model='pcr',\n",
    "                                       results=pcr_cv.cv_results_,\n",
    "                                       param_grid=n_components,\n",
    "                                       n_splits=10,\n",
    "                                       neg_mean_squared_error=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel('n components', fontsize=16)\n",
    "plt.ylabel('CV R2', fontsize=16)\n",
    "plt.scatter(n_components, R2_scores, s=30)\n",
    "plt.axvline(x=x_min, color='m')\n",
    "plt.axvline(x=x_1se, color='c')\n",
    "plt.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2_score = pcr_cv.best_score_\n",
    "print(\"Best R2 Score from Cross-Validation:\", best_r2_score)\n",
    "best_n_components = pcr_cv.best_params_['pca__n_components']\n",
    "print(\"Best n_components value:\", best_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pca n_components', x_1se)\n",
    "index_x_1se = np.where(n_components == x_1se)[0][0]\n",
    "\n",
    "# Get the corresponding R2 score\n",
    "R2_score_x_1se = R2_scores[index_x_1se]\n",
    "print(\"R2 Score corresponding to x_1se:\", R2_score_x_1se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(pcr_cv, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = True)\n",
    "# print_metrics(pcr_cv, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit the model with the selected parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(pca__n_components=x_1se)\n",
    "pipe.fit(X_train_lasso, y_train)\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(pipe, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = True)\n",
    "print_metrics(pipe, X_train_pcr, y_train, X_test_pcr, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation for Ridge Regression\n",
    "\n",
    "We can choose `alpha_max` so as the value that makes all coefficientes zero, and then construct a log sequence of `alpha` values trending smaller, decreasing the degree of regularization. \n",
    "\n",
    "For the case of `Ridge` Regression, alpha value that would make all coefficients zero would be `Inf`, however we can be satisfied with sufficiently small numbers, and work from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rr = X_train_poly_wide\n",
    "X_test_rr = X_test_poly_wide\n",
    "\n",
    "print(X_train_rr.shape, X_test_rr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine 'alpha_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha_max = 10**5\n",
    "rr = Ridge(alpha=alpha_max, random_state=88)\n",
    "rr.fit(X_train_rr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha_grid = {'alpha': np.logspace(-1, 5, num=50, base=10)}\n",
    "\n",
    "rr = Ridge(random_state=88)\n",
    "rr_cv = GridSearchCV(rr, alpha_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "rr_cv.fit(X_train_rr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = rr_cv.cv_results_['param_alpha'].data\n",
    "MSE_scores = rr_cv.cv_results_['mean_test_score']*(-1)\n",
    "x_min, x_1se = one_standard_error_rule(model='ridge',\n",
    "                                       results=rr_cv.cv_results_,\n",
    "                                       param_grid=range_alpha,\n",
    "                                       n_splits=10,\n",
    "                                       neg_mean_squared_error=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Alpha', fontsize=16)\n",
    "plt.ylabel('CV MSE', fontsize=16)\n",
    "plt.scatter(range_alpha, MSE_scores, s=30)\n",
    "plt.axvline(x=x_min, color='m')\n",
    "plt.axvline(x=x_1se, color='c')\n",
    "plt.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alpha one standard error rule:', x_1se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Refit with One Standard Error Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.set_params(alpha=x_1se)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "lasso.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = True)\n",
    "print_metrics(lasso, X_train_lasso, y_train, X_test_lasso, y_test, flag_log_sale_price = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
