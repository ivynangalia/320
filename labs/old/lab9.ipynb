{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw5o-c0odkX0"
   },
   "source": [
    "# STOR 320: Introduction to Data Science\n",
    "## Lab 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O1NhFft9e6oF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We use the following code to generate two columns of features and the target values. Based on the code below, what is the true linear model between `Target` and two features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>4.515377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>4.030911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.645894</td>\n",
       "      <td>3.335893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.437587</td>\n",
       "      <td>0.891773</td>\n",
       "      <td>2.980945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963663</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>5.527985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.398221</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>4.879017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.186193</td>\n",
       "      <td>0.944372</td>\n",
       "      <td>2.610245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.739551</td>\n",
       "      <td>0.490459</td>\n",
       "      <td>4.848061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.227415</td>\n",
       "      <td>0.254356</td>\n",
       "      <td>5.037529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.434417</td>\n",
       "      <td>4.160183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_1  Feature_2    Target\n",
       "0    0.548814   0.715189  4.515377\n",
       "1    0.602763   0.544883  4.030911\n",
       "2    0.423655   0.645894  3.335893\n",
       "3    0.437587   0.891773  2.980945\n",
       "4    0.963663   0.383442  5.527985\n",
       "..        ...        ...       ...\n",
       "95   0.398221   0.209844  4.879017\n",
       "96   0.186193   0.944372  2.610245\n",
       "97   0.739551   0.490459  4.848061\n",
       "98   0.227415   0.254356  5.037529\n",
       "99   0.058029   0.434417  4.160183\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Generate feature matrix X (100 samples, 2 features)\n",
    "X = np.random.rand(100, 2)\n",
    "\n",
    "# Define true coefficients for generating y\n",
    "true_beta = np.array([5, 2, -3])  # Intercept, beta_1, beta_2\n",
    "\n",
    "# Generate y with some added noise\n",
    "y = true_beta[0] + X @ true_beta[1:] + np.random.normal(0, 0.5, X.shape[0])\n",
    "\n",
    "# Combine X and y into a pandas DataFrame\n",
    "data = pd.DataFrame(np.column_stack((X, y)), columns=['Feature_1', 'Feature_2', 'Target'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true model is $y = 5 + 2 * F_1 - 3 * F_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Based on `data` table, separate X (features) and y (target) from the data. In other words, create a `100*2` numpy matrix for X and a numpy vector for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[[\"Feature_1\", \"Feature_2\"]]\n",
    "y = data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.715189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.645894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.437587</td>\n",
       "      <td>0.891773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963663</td>\n",
       "      <td>0.383442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.398221</td>\n",
       "      <td>0.209844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.186193</td>\n",
       "      <td>0.944372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.739551</td>\n",
       "      <td>0.490459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.227415</td>\n",
       "      <td>0.254356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.434417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_1  Feature_2\n",
       "0    0.548814   0.715189\n",
       "1    0.602763   0.544883\n",
       "2    0.423655   0.645894\n",
       "3    0.437587   0.891773\n",
       "4    0.963663   0.383442\n",
       "..        ...        ...\n",
       "95   0.398221   0.209844\n",
       "96   0.186193   0.944372\n",
       "97   0.739551   0.490459\n",
       "98   0.227415   0.254356\n",
       "99   0.058029   0.434417\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.515377\n",
       "1     4.030911\n",
       "2     3.335893\n",
       "3     2.980945\n",
       "4     5.527985\n",
       "        ...   \n",
       "95    4.879017\n",
       "96    2.610245\n",
       "97    4.848061\n",
       "98    5.037529\n",
       "99    4.160183\n",
       "Name: Target, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add a column of ones to X to account for the intercept term in the coefficient vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5488135 , 0.71518937],\n",
       "       [1.        , 0.60276338, 0.54488318],\n",
       "       [1.        , 0.4236548 , 0.64589411],\n",
       "       [1.        , 0.43758721, 0.891773  ],\n",
       "       [1.        , 0.96366276, 0.38344152],\n",
       "       [1.        , 0.79172504, 0.52889492],\n",
       "       [1.        , 0.56804456, 0.92559664],\n",
       "       [1.        , 0.07103606, 0.0871293 ],\n",
       "       [1.        , 0.0202184 , 0.83261985],\n",
       "       [1.        , 0.77815675, 0.87001215],\n",
       "       [1.        , 0.97861834, 0.79915856],\n",
       "       [1.        , 0.46147936, 0.78052918],\n",
       "       [1.        , 0.11827443, 0.63992102],\n",
       "       [1.        , 0.14335329, 0.94466892],\n",
       "       [1.        , 0.52184832, 0.41466194],\n",
       "       [1.        , 0.26455561, 0.77423369],\n",
       "       [1.        , 0.45615033, 0.56843395],\n",
       "       [1.        , 0.0187898 , 0.6176355 ],\n",
       "       [1.        , 0.61209572, 0.616934  ],\n",
       "       [1.        , 0.94374808, 0.6818203 ],\n",
       "       [1.        , 0.3595079 , 0.43703195],\n",
       "       [1.        , 0.6976312 , 0.06022547],\n",
       "       [1.        , 0.66676672, 0.67063787],\n",
       "       [1.        , 0.21038256, 0.1289263 ],\n",
       "       [1.        , 0.31542835, 0.36371077],\n",
       "       [1.        , 0.57019677, 0.43860151],\n",
       "       [1.        , 0.98837384, 0.10204481],\n",
       "       [1.        , 0.20887676, 0.16130952],\n",
       "       [1.        , 0.65310833, 0.2532916 ],\n",
       "       [1.        , 0.46631077, 0.24442559],\n",
       "       [1.        , 0.15896958, 0.11037514],\n",
       "       [1.        , 0.65632959, 0.13818295],\n",
       "       [1.        , 0.19658236, 0.36872517],\n",
       "       [1.        , 0.82099323, 0.09710128],\n",
       "       [1.        , 0.83794491, 0.09609841],\n",
       "       [1.        , 0.97645947, 0.4686512 ],\n",
       "       [1.        , 0.97676109, 0.60484552],\n",
       "       [1.        , 0.73926358, 0.03918779],\n",
       "       [1.        , 0.28280696, 0.12019656],\n",
       "       [1.        , 0.2961402 , 0.11872772],\n",
       "       [1.        , 0.31798318, 0.41426299],\n",
       "       [1.        , 0.0641475 , 0.69247212],\n",
       "       [1.        , 0.56660145, 0.26538949],\n",
       "       [1.        , 0.52324805, 0.09394051],\n",
       "       [1.        , 0.5759465 , 0.9292962 ],\n",
       "       [1.        , 0.31856895, 0.66741038],\n",
       "       [1.        , 0.13179786, 0.7163272 ],\n",
       "       [1.        , 0.28940609, 0.18319136],\n",
       "       [1.        , 0.58651293, 0.02010755],\n",
       "       [1.        , 0.82894003, 0.00469548],\n",
       "       [1.        , 0.67781654, 0.27000797],\n",
       "       [1.        , 0.73519402, 0.96218855],\n",
       "       [1.        , 0.24875314, 0.57615733],\n",
       "       [1.        , 0.59204193, 0.57225191],\n",
       "       [1.        , 0.22308163, 0.95274901],\n",
       "       [1.        , 0.44712538, 0.84640867],\n",
       "       [1.        , 0.69947928, 0.29743695],\n",
       "       [1.        , 0.81379782, 0.39650574],\n",
       "       [1.        , 0.8811032 , 0.58127287],\n",
       "       [1.        , 0.88173536, 0.69253159],\n",
       "       [1.        , 0.72525428, 0.50132438],\n",
       "       [1.        , 0.95608363, 0.6439902 ],\n",
       "       [1.        , 0.42385505, 0.60639321],\n",
       "       [1.        , 0.0191932 , 0.30157482],\n",
       "       [1.        , 0.66017354, 0.29007761],\n",
       "       [1.        , 0.61801543, 0.4287687 ],\n",
       "       [1.        , 0.13547406, 0.29828233],\n",
       "       [1.        , 0.56996491, 0.59087276],\n",
       "       [1.        , 0.57432525, 0.65320082],\n",
       "       [1.        , 0.65210327, 0.43141844],\n",
       "       [1.        , 0.8965466 , 0.36756187],\n",
       "       [1.        , 0.43586493, 0.89192336],\n",
       "       [1.        , 0.80619399, 0.70388858],\n",
       "       [1.        , 0.10022689, 0.91948261],\n",
       "       [1.        , 0.7142413 , 0.99884701],\n",
       "       [1.        , 0.1494483 , 0.86812606],\n",
       "       [1.        , 0.16249293, 0.61555956],\n",
       "       [1.        , 0.12381998, 0.84800823],\n",
       "       [1.        , 0.80731896, 0.56910074],\n",
       "       [1.        , 0.4071833 , 0.069167  ],\n",
       "       [1.        , 0.69742877, 0.45354268],\n",
       "       [1.        , 0.7220556 , 0.86638233],\n",
       "       [1.        , 0.97552151, 0.85580334],\n",
       "       [1.        , 0.01171408, 0.35997806],\n",
       "       [1.        , 0.72999056, 0.17162968],\n",
       "       [1.        , 0.52103661, 0.05433799],\n",
       "       [1.        , 0.19999652, 0.01852179],\n",
       "       [1.        , 0.7936977 , 0.22392469],\n",
       "       [1.        , 0.34535168, 0.92808129],\n",
       "       [1.        , 0.7044144 , 0.03183893],\n",
       "       [1.        , 0.16469416, 0.6214784 ],\n",
       "       [1.        , 0.57722859, 0.23789282],\n",
       "       [1.        , 0.934214  , 0.61396596],\n",
       "       [1.        , 0.5356328 , 0.58990998],\n",
       "       [1.        , 0.73012203, 0.311945  ],\n",
       "       [1.        , 0.39822106, 0.20984375],\n",
       "       [1.        , 0.18619301, 0.94437239],\n",
       "       [1.        , 0.7395508 , 0.49045881],\n",
       "       [1.        , 0.22741463, 0.25435648],\n",
       "       [1.        , 0.05802916, 0.43441663]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_with_intercept = np.column_stack((np.ones(x.shape[0]), x))\n",
    "x_with_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate the estimation of parameter $\\beta$ manually using NumPy's matrix operations.\n",
    "- Hint: You can refer to the lecture notes to find the closed-form solution for the regression coefficients\n",
    "- Hint: You can use `np.linalg.inv` to calculate the inverse of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually calculated beta: [ 5.05725163  1.78685022 -2.98521247]\n"
     ]
    }
   ],
   "source": [
    "XTX_inv = np.linalg.inv(x_with_intercept.T @ x_with_intercept)\n",
    "beta_hat = XTX_inv @ x_with_intercept.T @ y\n",
    "print(f\"Manually calculated beta: {beta_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute $R$ squared manually. You can refer to the lecture notes to see the definitino of R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308337212672314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = x_with_intercept @ beta_hat\n",
    "SS_res = np.sum((y - y_pred) ** 2)\n",
    "SS_total = np.sum((y - np.mean(y)) ** 2)\n",
    "R_squared = 1 - (SS_res/SS_total)\n",
    "R_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Comparison with statsmodels**\n",
    "\n",
    "We fit a linear regression model using `statsmodels`, then print and compare both the manually calculated coefficients and R-squared values with those from statsmodels. Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Target</td>      <th>  R-squared:         </th> <td>   0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   238.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 03 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.74e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:37:57</td>     <th>  Log-Likelihood:    </th> <td> -64.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   134.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   142.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    5.0573</td> <td>    0.130</td> <td>   39.044</td> <td> 0.000</td> <td>    4.800</td> <td>    5.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Feature_1</th> <td>    1.7869</td> <td>    0.166</td> <td>   10.750</td> <td> 0.000</td> <td>    1.457</td> <td>    2.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Feature_2</th> <td>   -2.9852</td> <td>    0.164</td> <td>  -18.217</td> <td> 0.000</td> <td>   -3.310</td> <td>   -2.660</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.410</td> <th>  Durbin-Watson:     </th> <td>   2.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.815</td> <th>  Jarque-Bera (JB):  </th> <td>   0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.144</td> <th>  Prob(JB):          </th> <td>   0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.807</td> <th>  Cond. No.          </th> <td>    5.58</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Target      & \\textbf{  R-squared:         } &     0.831   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.827   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     238.2   \\\\\n",
       "\\textbf{Date:}             & Sun, 03 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.74e-38   \\\\\n",
       "\\textbf{Time:}             &     11:37:57     & \\textbf{  Log-Likelihood:    } &   -64.212   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     134.4   \\\\\n",
       "\\textbf{Df Residuals:}     &          97      & \\textbf{  BIC:               } &     142.2   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}      &       5.0573  &        0.130     &    39.044  &         0.000        &        4.800    &        5.314     \\\\\n",
       "\\textbf{Feature\\_1} &       1.7869  &        0.166     &    10.750  &         0.000        &        1.457    &        2.117     \\\\\n",
       "\\textbf{Feature\\_2} &      -2.9852  &        0.164     &   -18.217  &         0.000        &       -3.310    &       -2.660     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.410 & \\textbf{  Durbin-Watson:     } &    2.045  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.815 & \\textbf{  Jarque-Bera (JB):  } &    0.502  \\\\\n",
       "\\textbf{Skew:}          &  0.144 & \\textbf{  Prob(JB):          } &    0.778  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.807 & \\textbf{  Cond. No.          } &     5.58  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Target   R-squared:                       0.831\n",
       "Model:                            OLS   Adj. R-squared:                  0.827\n",
       "Method:                 Least Squares   F-statistic:                     238.2\n",
       "Date:                Sun, 03 Nov 2024   Prob (F-statistic):           3.74e-38\n",
       "Time:                        11:37:57   Log-Likelihood:                -64.212\n",
       "No. Observations:                 100   AIC:                             134.4\n",
       "Df Residuals:                      97   BIC:                             142.2\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0573      0.130     39.044      0.000       4.800       5.314\n",
       "Feature_1      1.7869      0.166     10.750      0.000       1.457       2.117\n",
       "Feature_2     -2.9852      0.164    -18.217      0.000      -3.310      -2.660\n",
       "==============================================================================\n",
       "Omnibus:                        0.410   Durbin-Watson:                   2.045\n",
       "Prob(Omnibus):                  0.815   Jarque-Bera (JB):                0.502\n",
       "Skew:                           0.144   Prob(JB):                        0.778\n",
       "Kurtosis:                       2.807   Cond. No.                         5.58\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm = sm.add_constant(x)\n",
    "mod = sm.OLS(y, x_sm)\n",
    "results = mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
